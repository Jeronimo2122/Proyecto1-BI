{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto: Turismo de los Alpes  - Grupo 34\n",
    "Felipe Nuñez - 202021673\n",
    "<br>\n",
    "Jeronimo Vargas Rendon - 202113305\n",
    "<br>\n",
    "Juan Manuel Pérez - 202021827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\JUAN M PEREZ\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\JUAN M PEREZ\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import stanza\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_csv('tipo1_entrenamiento_estudiantes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Class\n",
      "0  Nos alojamos en una casa alquilada en la ciuda...      4\n",
      "1  La comida está bien, pero nada especial. Yo te...      3\n",
      "2  En mi opinión, no es una como muchos usuarios ...      3\n",
      "3  esta curiosa forma que asemeja una silla de mo...      4\n",
      "4  Lo mejor era la limonada. Me gusto la comida d...      2\n",
      "Total de registros: 7875\n"
     ]
    }
   ],
   "source": [
    "# Visualización de los primeros registros\n",
    "print(df.head())\n",
    "\n",
    "# Total de registros\n",
    "print(\"Total de registros:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De entrada tenemos que se encuentran 7875 observaciones, y hay dos variables. La primera es la variable Review que es una cadena de cáracteres y hace referencia a el comentario de los viajeros. La segunda variable es Class, esta variable es nuestra variable objetivo pues esta representa la satisfaccion del viajero.\n",
    "\n",
    "Analisis de Dimension de calidad de datos:\n",
    "### - Unicidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados: 71\n"
     ]
    }
   ],
   "source": [
    "#Contar duplicados\n",
    "print(\"Duplicados:\" , df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 71 observaciones duplicadas, es necesario eliminar las filas repetidas y dejar solo una observación. Ya que dejarlas incrementaria los efectos de algunas palabras dada su repetición en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Completitud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificación de valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay valores nulos los datos estan completos. Se cumple completitud.\n",
    "\n",
    "### - Validez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7804.000000\n",
       "mean        3.500128\n",
       "std         1.324219\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    object\n",
       "Class      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos cumplen con el formato esperado. La varible objetivo cumple con el rango esperado entre 1 y 5. Pues para Review se puede observar que es de tipo object el cual hace referencia a una cadena de textos.\n",
    "\n",
    "### - Consistencia:\n",
    "Si cumple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparación de los datos\n",
    "\n",
    "### Limpieza de los datos:\n",
    "\n",
    "Para este proceso de limpieza de datos es necesario hacer una limpieza de las palabras que no agregan valor. Para esto se definio la función remove_ noise que se encarga de eliminar ciertos tipos de ruido o elementos no deseados del texto antes de continuar con el proceso de limpieza.\n",
    "\n",
    "1. re.sub(r'<.*?>', '', text): Utiliza expresiones regulares para eliminar todas las etiquetas HTML presentes en el texto. Esto es importante si estás trabajando con texto extraído de páginas web o documentos HTML, ya que las etiquetas HTML no proporcionan información útil para el análisis de texto y pueden interferir con los procesos de limpieza y análisis posteriores.\n",
    "\n",
    "2. re.sub(r'[0-9]+', '', text): Utiliza expresiones regulares para eliminar todos los números del texto. Al observar algunas de los Review muchos de los números que se encontraban, hacen referencia a fechas o horas. Por esta razón, consideramos que los numeros no agregaban valor a estos comentarios y se eliminaron los números de los comentarios.\n",
    "\n",
    "3. re.sub(r'[^a-záéíóúñA-ZÁÉÍÓÚÑ\\s]', '', text): Utiliza expresiones regulares para eliminar todos los caracteres especiales excepto los espacios en blanco y los caracteres alfabéticos (incluyendo letras con tilde y la ñ). Esto es útil para eliminar signos de puntuación, símbolos y otros caracteres que no aportan significado semántico al texto. Sin embargo, conserva los espacios en blanco para preservar la estructura del texto.\n",
    "\n",
    "4. re.sub(r'\\s+', ' ', text): Utiliza expresiones regulares para reemplazar múltiples espacios en blanco consecutivos por un solo espacio en blanco. Esto ayuda a normalizar la cantidad de espacios en el texto, lo que facilita el procesamiento posterior.\n",
    "\n",
    "5. text = text.lower(): Convierte todo el texto a minúsculas. Esto es importante para garantizar la consistencia en el texto y evitar problemas de diferenciación entre mayúsculas y minúsculas durante el análisis.\n",
    "\n",
    "La otra función que se definio es clean_text, que se encarga de las \"stopwords\". Las \"stopwords\" son palabras que se filtran del texto durante el análisis de procesamiento del lenguaje natural (NLP) porque no aportan un significado contextual importante para el análisis. La función especificamente tokeniza el texto en palabras y luego filtra aquellas que no son stopwords ni caracteres alfabéticos, reconstruyendo el texto sin las stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Eliminar HTML tags\n",
    "    text = re.sub(r'[0-9]+', '', text) # Elimnar numeros\n",
    "    text = re.sub(r'[^a-záéíóúñA-ZÁÉÍÓÚÑ\\s]', '', text)  # Eliminar caracteres especiales\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Definición de las stopwords en español\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def clean_text(text):\n",
    "    words = word_tokenize(text)  # Tokenizar el texto en palabras\n",
    "    filtered_words = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    # Reconstrucción del texto\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def preprocessing(text):\n",
    "    cleaned_text = remove_noise(text)  # Remover ruido del texto\n",
    "    cleaned_words = clean_text(cleaned_text)  # Limpiar el texto\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>palabras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>alojamos casa alquilada ciudad amurallada pare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>comida bien especial mejor comida mexcan unido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>opinión usuarios reclaman gran paladar parece ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>curiosa forma asemeja silla montar ahi nombre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>mejor limonada gusto comida mundo sosa frío</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2   \n",
       "\n",
       "                                            palabras  \n",
       "0  alojamos casa alquilada ciudad amurallada pare...  \n",
       "1  comida bien especial mejor comida mexcan unido...  \n",
       "2  opinión usuarios reclaman gran paladar parece ...  \n",
       "3  curiosa forma asemeja silla montar ahi nombre ...  \n",
       "4        mejor limonada gusto comida mundo sosa frío  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['palabras']=df['Review'].apply(preprocessing)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tokenización se observa que se aplica la funcion de preprocesamiento que se explico anteriormente. Como resultado de esta tokenización preprocesada, se obtienen únicamente las palabras que cuentan con un sentido semántico. Esto significa que las palabras resultantes después del preprocesamiento son aquellas que tienen relevancia para el análisis de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización:\n",
    "\n",
    "El objetivo principal de la lematización es reducir las palabras a su forma canónica para facilitar el análisis semántico. Para esto se utilizo la libreria de Stanza desarrollada por el grupo de investigación de la Universidad de Stanford. En la siguiente función, Stanza realiza la lematización de las palabras en español. Después de procesar el texto, Stanza identifica y reemplaza cada palabra con su lema correspondiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849af833bf444e8a9cb8cc9306f732b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 19:30:56 INFO: Downloaded file to C:\\Users\\JUAN M PEREZ S\\stanza_resources\\resources.json\n",
      "2024-04-06 19:30:56 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2024-04-06 19:31:00 INFO: File exists: C:\\Users\\JUAN M PEREZ S\\stanza_resources\\es\\default.zip\n",
      "2024-04-06 19:31:08 INFO: Finished downloading models and saved to C:\\Users\\JUAN M PEREZ S\\stanza_resources\n",
      "2024-04-06 19:31:08 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e1c2729c654cd2ab9783cd631607e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 19:31:08 INFO: Downloaded file to C:\\Users\\JUAN M PEREZ S\\stanza_resources\\resources.json\n",
      "2024-04-06 19:31:08 WARNING: Language es package default expects mwt, which has been added\n",
      "2024-04-06 19:31:08 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | ancora          |\n",
      "| mwt       | ancora          |\n",
      "| lemma     | ancora_nocharlm |\n",
      "===============================\n",
      "\n",
      "2024-04-06 19:31:08 INFO: Using device: cpu\n",
      "2024-04-06 19:31:08 INFO: Loading: tokenize\n",
      "2024-04-06 19:31:10 INFO: Loading: mwt\n",
      "2024-04-06 19:31:10 INFO: Loading: lemma\n",
      "2024-04-06 19:31:11 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>palabras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>alojamo casa alquilada ciudad amurallada parec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>comida bien especial mejor comida mexcan unido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>opinión usuario reclamar gran paladar parecer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>curioso forma asemejar silla montar ahi nombre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>mejor limonada gusto comida mundo sosa frío</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2   \n",
       "\n",
       "                                            palabras  \n",
       "0  alojamo casa alquilada ciudad amurallada parec...  \n",
       "1  comida bien especial mejor comida mexcan unido...  \n",
       "2  opinión usuario reclamar gran paladar parecer ...  \n",
       "3  curioso forma asemejar silla montar ahi nombre...  \n",
       "4        mejor limonada gusto comida mundo sosa frío  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza.download('es')\n",
    "\n",
    "nlp = stanza.Pipeline(lang='es', processors='tokenize,lemma')\n",
    "\n",
    "def process_text_stanza(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "    return lemmatized_text\n",
    "\n",
    "df['palabras'] = df['palabras'].apply(process_text_stanza)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación:\n",
    "Para poder realizar un modelo analisis de textos es necesario representar el texto númericamente para poder aplicar los algoritmos de aprendizaje automatico. Hay diferentes transformaciones posibles, se probaron 3: \n",
    "- Term Frequency Inverse Document Frequency\n",
    "- Count vectorizer\n",
    "- Count Vectorizer Dummy\n",
    "\n",
    "1. Term Frequency Inverse Document Frequency:\n",
    "Es una medida estadistica que evalua la importancia de una palabra en el Review. Creando una matriz por cada Review y cada termino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['palabras']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Count Vectorizer:\n",
    "Cuenta la frecuencia de ocurrencia de cada palabra en cada Review. Por esta razon construye una matriz de ocurrencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7804, 21183)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "X_count = count.fit_transform(df['palabras'])\n",
    "print(X_count.shape)\n",
    "X_count.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Count Vectorizer Binario:\n",
    "Cuenta las ocurrencias de palabras, simplemente marca la presencia o ausencia de una palabra en un Review utilizando valores binarios (1 para presencia, 0 para ausencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7804, 21183)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = CountVectorizer(binary=True)\n",
    "X_dummy = dummy.fit_transform(df['palabras'])\n",
    "print(X_dummy.shape)\n",
    "X_dummy.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que se realizaron 3 transformaciones se corrieron tres modelos con los algoritmos seleccionados para compararlos basandonos en sus metricas y escoger el modelo que mejor se adapte a el contexto. Por esta razon, se definieron 3 sets de datos dependiendo de la transformacion en el que se realizo un 70% de entrenamiento y un 30% de los datos para la prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_count, y, test_size=0.3, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_dummy, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Term Frequency Inverse Document Frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.37      0.44       246\n",
      "           2       0.42      0.34      0.37       354\n",
      "           3       0.38      0.37      0.38       463\n",
      "           4       0.38      0.40      0.39       603\n",
      "           5       0.58      0.69      0.63       676\n",
      "\n",
      "    accuracy                           0.46      2342\n",
      "   macro avg       0.46      0.43      0.44      2342\n",
      "weighted avg       0.46      0.46      0.46      2342\n",
      "\n",
      "Accuracy: 0.4645602049530316\n"
     ]
    }
   ],
   "source": [
    "# Regression logistica\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(X_train, y_train)\n",
    "y_pred = modelLR.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo realizado fue una regresión logistica para el set de datos de Term Frequency Inverse Document Frequency. La precisión global del modelo es del 46.46%, lo que significa que el modelo clasifica correctamente el 46.46% de las muestras del conjunto de prueba. El recall es de 0.46 y este indentifica todas las muestras positivas. El F1-Score fue de 0.46 y esta medida combina la precision y el recall, se espera que este valor sea lo más cercano a 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.19      0.29       246\n",
      "           2       0.42      0.39      0.40       354\n",
      "           3       0.38      0.30      0.34       463\n",
      "           4       0.40      0.39      0.39       603\n",
      "           5       0.53      0.76      0.62       676\n",
      "\n",
      "    accuracy                           0.46      2342\n",
      "   macro avg       0.46      0.41      0.41      2342\n",
      "weighted avg       0.45      0.46      0.44      2342\n",
      "\n",
      "Accuracy: 0.45815542271562765\n"
     ]
    }
   ],
   "source": [
    "# Modelo multinomial Naive Bayes\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train, y_train)\n",
    "y_pred = modelNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo realizado fue un multinomial Naive Bayes para el set de datos de Term Frequency Inverse Document Frequency. La precisión global del modelo es del 45.82%, lo que significa que el modelo clasifica correctamente el 45.82% de las muestras del conjunto de prueba. El recall es de 0.46 y este indentifica todas las muestras positivas. El F1-Score fue de 0.44 y esta medida combina la precision y el recall, se espera que este valor sea lo más cercano a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.22      0.30       246\n",
      "           2       0.38      0.37      0.37       354\n",
      "           3       0.37      0.31      0.34       463\n",
      "           4       0.39      0.35      0.37       603\n",
      "           5       0.51      0.72      0.60       676\n",
      "\n",
      "    accuracy                           0.44      2342\n",
      "   macro avg       0.43      0.39      0.40      2342\n",
      "weighted avg       0.43      0.44      0.42      2342\n",
      "\n",
      "Accuracy: 0.4385140905209223\n"
     ]
    }
   ],
   "source": [
    "# Modelo Random Forest\n",
    "\n",
    "modelRF = RandomForestClassifier()\n",
    "modelRF.fit(X_train, y_train)\n",
    "y_pred = modelRF.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo realizado fue un Random Forest para el set de datos de Term Frequency Inverse Document Frequency. La precisión global del modelo es del 43.85% el menor en los resultados del set. El recall es de 0.44 y este indentifica todas las muestras positivas. El F1-Score fue de 0.42 y esta medida combina la precision y el recall. En terminos generales este entre los primeros 3 modelos, este modelo es el que cuenta con peores resultados.\n",
    "\n",
    "2. Count Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.43      0.46       246\n",
      "           2       0.40      0.30      0.34       354\n",
      "           3       0.38      0.38      0.38       463\n",
      "           4       0.39      0.40      0.40       603\n",
      "           5       0.58      0.67      0.62       676\n",
      "\n",
      "    accuracy                           0.46      2342\n",
      "   macro avg       0.45      0.44      0.44      2342\n",
      "weighted avg       0.46      0.46      0.46      2342\n",
      "\n",
      "Accuracy: 0.4632792485055508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regression logistica\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(X_train2, y_train2)\n",
    "y_pred = modelLR.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test2, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.20      0.29       246\n",
      "           2       0.38      0.39      0.39       354\n",
      "           3       0.37      0.32      0.35       463\n",
      "           4       0.39      0.45      0.42       603\n",
      "           5       0.61      0.71      0.65       676\n",
      "\n",
      "    accuracy                           0.46      2342\n",
      "   macro avg       0.47      0.41      0.42      2342\n",
      "weighted avg       0.47      0.46      0.45      2342\n",
      "\n",
      "Accuracy: 0.46498719043552517\n"
     ]
    }
   ],
   "source": [
    "# Modelo multinomial Naive Bayes\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train2, y_train2)\n",
    "y_pred = modelNB.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test2, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.16      0.25       246\n",
      "           2       0.44      0.34      0.38       354\n",
      "           3       0.36      0.28      0.31       463\n",
      "           4       0.37      0.34      0.35       603\n",
      "           5       0.48      0.78      0.60       676\n",
      "\n",
      "    accuracy                           0.43      2342\n",
      "   macro avg       0.44      0.38      0.38      2342\n",
      "weighted avg       0.43      0.43      0.41      2342\n",
      "\n",
      "Accuracy: 0.43424423569598636\n"
     ]
    }
   ],
   "source": [
    "# Modelo Random Forest\n",
    "\n",
    "modelRF = RandomForestClassifier()\n",
    "modelRF.fit(X_train2, y_train2)\n",
    "y_pred = modelRF.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test2, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Count Vectorizer Binario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.42      0.45       246\n",
      "           2       0.40      0.30      0.34       354\n",
      "           3       0.39      0.38      0.38       463\n",
      "           4       0.39      0.41      0.40       603\n",
      "           5       0.58      0.66      0.62       676\n",
      "\n",
      "    accuracy                           0.46      2342\n",
      "   macro avg       0.45      0.43      0.44      2342\n",
      "weighted avg       0.45      0.46      0.45      2342\n",
      "\n",
      "Accuracy: 0.4594363791631085\n"
     ]
    }
   ],
   "source": [
    "# Regression logistica\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(X_train3, y_train3)\n",
    "y_pred = modelLR.predict(X_test3)\n",
    "print(classification_report(y_test3, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test3, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.15      0.24       246\n",
      "           2       0.39      0.40      0.40       354\n",
      "           3       0.37      0.32      0.34       463\n",
      "           4       0.39      0.46      0.42       603\n",
      "           5       0.60      0.72      0.65       676\n",
      "\n",
      "    accuracy                           0.46      2342\n",
      "   macro avg       0.47      0.41      0.41      2342\n",
      "weighted avg       0.47      0.46      0.45      2342\n",
      "\n",
      "Accuracy: 0.4637062339880444\n"
     ]
    }
   ],
   "source": [
    "# Modelo multinomial Naive Bayes\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train3, y_train3)\n",
    "y_pred = modelNB.predict(X_test3)\n",
    "print(classification_report(y_test3, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test3, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.18      0.27       246\n",
      "           2       0.40      0.30      0.34       354\n",
      "           3       0.35      0.27      0.30       463\n",
      "           4       0.38      0.36      0.37       603\n",
      "           5       0.48      0.79      0.60       676\n",
      "\n",
      "    accuracy                           0.44      2342\n",
      "   macro avg       0.44      0.38      0.38      2342\n",
      "weighted avg       0.43      0.44      0.41      2342\n",
      "\n",
      "Accuracy: 0.43552519214346713\n"
     ]
    }
   ],
   "source": [
    "# Modelo Random Forest\n",
    "\n",
    "modelRF = RandomForestClassifier()\n",
    "modelRF.fit(X_train3, y_train3)\n",
    "y_pred = modelRF.predict(X_test3)\n",
    "print(classification_report(y_test3, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test3, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selección del modelo\n",
    "\n",
    "Basado en las metricas anteriores el modelo que se considera mejor es:\n",
    "Multinomial Naive Bayes utilizando la transformacion de Count Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo multinomial Naive Bayes\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train2, y_train2)\n",
    "y_pred = modelNB.predict(X_test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicciones Archivo de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con el modelo a los siguientes Datos usando el mejor modelo LR\n",
    "\n",
    "df_pred = pd.read_csv('particion_prueba_estudiantes.csv')\n",
    "\n",
    "df_p = df_pred.copy()\n",
    "\n",
    "# Predecir con el modleo de Liner Regression\n",
    "df_p['Review'] = df_p['Review'].apply(remove_noise)\n",
    "df_p['Review'] = df_p['Review'].apply(clean_text)\n",
    "df_p['Review'] = df_p['Review'].apply(normalize_text)\n",
    "df_p['Review'] = df_p['Review'].apply(preprocess_text)\n",
    "X_pred = vectorizer.transform(df_p['Review']).toarray()\n",
    "y_pred = modelLR.predict(X_pred)\n",
    "df_p['Class'] = y_pred\n",
    "\n",
    "# Guardar predicciones\n",
    "df_pred['Class'] = y_pred\n",
    "df_pred.to_csv('predicciones_estudiantes.csv', index=False)\n",
    "print(df_p.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
