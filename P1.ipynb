{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto: Turismo de los Alpes  - Grupo 34\n",
    "Felipe Nuñez - 202021673\n",
    "<br>\n",
    "Jeronimo Vargas Rendon - 202113305\n",
    "<br>\n",
    "Juan Manuel Pérez - 202021827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\JUAN M PEREZ\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\JUAN M PEREZ\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import stanza\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_csv('tipo1_entrenamiento_estudiantes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Class\n",
      "0  Nos alojamos en una casa alquilada en la ciuda...      4\n",
      "1  La comida está bien, pero nada especial. Yo te...      3\n",
      "2  En mi opinión, no es una como muchos usuarios ...      3\n",
      "3  esta curiosa forma que asemeja una silla de mo...      4\n",
      "4  Lo mejor era la limonada. Me gusto la comida d...      2\n",
      "Total de registros: 7875\n"
     ]
    }
   ],
   "source": [
    "# Visualización de los primeros registros\n",
    "print(df.head())\n",
    "\n",
    "# Total de registros\n",
    "print(\"Total de registros:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De entrada tenemos que se encuentran 7875 observaciones, y hay dos variables. La primera es la variable Review que es una cadena de cáracteres y hace referencia a el comentario de los viajeros. La segunda variable es Class, esta variable es nuestra variable objetivo pues esta representa la satisfaccion del viajero.\n",
    "\n",
    "Analisis de Dimension de calidad de datos:\n",
    "### - Unicidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados: 71\n"
     ]
    }
   ],
   "source": [
    "#Contar duplicados\n",
    "print(\"Duplicados:\" , df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 71 observaciones duplicadas, es necesario eliminar las filas repetidas y dejar solo una observación. Ya que dejarlas incrementaria los efectos de algunas palabras dada su repetición en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Completitud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificación de valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay valores nulos los datos estan completos. Se cumple completitud.\n",
    "\n",
    "### - Validez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7804.000000\n",
       "mean        3.500128\n",
       "std         1.324219\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    object\n",
       "Class      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos cumplen con el formato esperado. La varible objetivo cumple con el rango esperado entre 1 y 5. Pues para Review se puede observar que es de tipo object el cual hace referencia a una cadena de textos.\n",
    "\n",
    "### - Consistencia:\n",
    "Si cumple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparación de los datos\n",
    "\n",
    "### Limpieza de los datos:\n",
    "\n",
    "Para este proceso de limpieza de datos es necesario hacer una limpieza de las palabras que no agregan valor. Para esto se definio la función remove_ noise que se encarga de eliminar ciertos tipos de ruido o elementos no deseados del texto antes de continuar con el proceso de limpieza.\n",
    "\n",
    "1. re.sub(r'<.*?>', '', text): Utiliza expresiones regulares para eliminar todas las etiquetas HTML presentes en el texto. Esto es importante si estás trabajando con texto extraído de páginas web o documentos HTML, ya que las etiquetas HTML no proporcionan información útil para el análisis de texto y pueden interferir con los procesos de limpieza y análisis posteriores.\n",
    "\n",
    "2. re.sub(r'[0-9]+', '', text): Utiliza expresiones regulares para eliminar todos los números del texto. Al observar algunas de los Review muchos de los números que se encontraban, hacen referencia a fechas o horas. Por esta razón, consideramos que los numeros no agregaban valor a estos comentarios y se eliminaron los números de los comentarios.\n",
    "\n",
    "3. re.sub(r'[^a-záéíóúñA-ZÁÉÍÓÚÑ\\s]', '', text): Utiliza expresiones regulares para eliminar todos los caracteres especiales excepto los espacios en blanco y los caracteres alfabéticos (incluyendo letras con tilde y la ñ). Esto es útil para eliminar signos de puntuación, símbolos y otros caracteres que no aportan significado semántico al texto. Sin embargo, conserva los espacios en blanco para preservar la estructura del texto.\n",
    "\n",
    "4. re.sub(r'\\s+', ' ', text): Utiliza expresiones regulares para reemplazar múltiples espacios en blanco consecutivos por un solo espacio en blanco. Esto ayuda a normalizar la cantidad de espacios en el texto, lo que facilita el procesamiento posterior.\n",
    "\n",
    "5. text = text.lower(): Convierte todo el texto a minúsculas. Esto es importante para garantizar la consistencia en el texto y evitar problemas de diferenciación entre mayúsculas y minúsculas durante el análisis.\n",
    "\n",
    "La otra función que se definio es clean_text, que se encarga de las \"stopwords\". Las \"stopwords\" son palabras que se filtran del texto durante el análisis de procesamiento del lenguaje natural (NLP) porque no aportan un significado contextual importante para el análisis. La función especificamente tokeniza el texto en palabras y luego filtra aquellas que no son stopwords ni caracteres alfabéticos, reconstruyendo el texto sin las stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Eliminar HTML tags\n",
    "    text = re.sub(r'[0-9]+', '', text) # Elimnar numeros\n",
    "    text = re.sub(r'[^a-záéíóúñA-ZÁÉÍÓÚÑ\\s]', '', text)  # Eliminar caracteres especiales\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Definición de las stopwords en español\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def clean_text(text):\n",
    "    words = word_tokenize(text)  # Tokenizar el texto en palabras\n",
    "    filtered_words = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    # Reconstrucción del texto\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def preprocessing(text):\n",
    "    cleaned_text = remove_noise(text)  # Remover ruido del texto\n",
    "    cleaned_words = clean_text(cleaned_text)  # Limpiar el texto\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>palabras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>alojamos casa alquilada ciudad amurallada pare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>comida bien especial mejor comida mexcan unido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>opinión usuarios reclaman gran paladar parece ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>curiosa forma asemeja silla montar ahi nombre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>mejor limonada gusto comida mundo sosa frío</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2   \n",
       "\n",
       "                                            palabras  \n",
       "0  alojamos casa alquilada ciudad amurallada pare...  \n",
       "1  comida bien especial mejor comida mexcan unido...  \n",
       "2  opinión usuarios reclaman gran paladar parece ...  \n",
       "3  curiosa forma asemeja silla montar ahi nombre ...  \n",
       "4        mejor limonada gusto comida mundo sosa frío  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['palabras']=df['Review'].apply(preprocessing)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tokenización se observa que se aplica la funcion de preprocesamiento que se explico anteriormente. Como resultado de esta tokenización preprocesada, se obtienen únicamente las palabras que cuentan con un sentido semántico. Esto significa que las palabras resultantes después del preprocesamiento son aquellas que tienen relevancia para el análisis de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización:\n",
    "\n",
    "El objetivo principal de la lematización es reducir las palabras a su forma canónica para facilitar el análisis semántico. Para esto se utilizo la libreria de Stanza desarrollada por el grupo de investigación de la Universidad de Stanford. En la siguiente función, Stanza realiza la lematización de las palabras en español. Después de procesar el texto, Stanza identifica y reemplaza cada palabra con su lema correspondiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')\n",
    "def normalize_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmas)\n",
    "df['palabras'] = df['palabras'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e22287eb79e4f5690cdbfe6a6ca281d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 06:37:43 INFO: Downloaded file to C:\\Users\\JUAN M PEREZ S\\stanza_resources\\resources.json\n",
      "2024-04-05 06:37:43 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2024-04-05 06:37:46 INFO: File exists: C:\\Users\\JUAN M PEREZ S\\stanza_resources\\es\\default.zip\n",
      "2024-04-05 06:37:52 INFO: Finished downloading models and saved to C:\\Users\\JUAN M PEREZ S\\stanza_resources\n",
      "2024-04-05 06:37:52 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c92912edbfd45c8bdda286db05d7ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 06:37:53 INFO: Downloaded file to C:\\Users\\JUAN M PEREZ S\\stanza_resources\\resources.json\n",
      "2024-04-05 06:37:53 WARNING: Language es package default expects mwt, which has been added\n",
      "2024-04-05 06:37:53 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | ancora          |\n",
      "| mwt       | ancora          |\n",
      "| lemma     | ancora_nocharlm |\n",
      "===============================\n",
      "\n",
      "2024-04-05 06:37:53 INFO: Using device: cpu\n",
      "2024-04-05 06:37:53 INFO: Loading: tokenize\n",
      "2024-04-05 06:37:54 INFO: Loading: mwt\n",
      "2024-04-05 06:37:54 INFO: Loading: lemma\n",
      "2024-04-05 06:37:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('es')\n",
    "\n",
    "nlp = stanza.Pipeline(lang='es', processors='tokenize,lemma')\n",
    "\n",
    "def process_text_stanza(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "    return lemmatized_text\n",
    "\n",
    "df['palabras'] = df['palabras'].apply(process_text_stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>palabras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>alojamo casa alquilada ciudad amurallada parec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>comida bien especial mejor comida mexcan unido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>opinión usuario reclamar gran paladar parecer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>curioso forma asemejar silla montar ahi nombre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>mejor limonada gusto comida mundo sosa frío</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>motivo estancia venir congreso medico hospedar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>difícil revisar castillo apenas poder caminar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>si ir mérida poder perderte lugar nuevo sucurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre del...</td>\n",
       "      <td>5</td>\n",
       "      <td>imperdible sitio llevar nombre conquistador jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia del Amor y Amistad\\r\\n\\r\\nTe re...</td>\n",
       "      <td>3</td>\n",
       "      <td>festejando dia amor amistad remontar restauran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7804 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2   \n",
       "...                                                 ...    ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5   \n",
       "7873  Este imperdible sitio, que lleva el nombre del...      5   \n",
       "7874  Festejando Dia del Amor y Amistad\\r\\n\\r\\nTe re...      3   \n",
       "\n",
       "                                               palabras  \n",
       "0     alojamo casa alquilada ciudad amurallada parec...  \n",
       "1     comida bien especial mejor comida mexcan unido...  \n",
       "2     opinión usuario reclamar gran paladar parecer ...  \n",
       "3     curioso forma asemejar silla montar ahi nombre...  \n",
       "4           mejor limonada gusto comida mundo sosa frío  \n",
       "...                                                 ...  \n",
       "7870  motivo estancia venir congreso medico hospedar...  \n",
       "7871  difícil revisar castillo apenas poder caminar ...  \n",
       "7872  si ir mérida poder perderte lugar nuevo sucurs...  \n",
       "7873  imperdible sitio llevar nombre conquistador jo...  \n",
       "7874  festejando dia amor amistad remontar restauran...  \n",
       "\n",
       "[7804 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['palabras']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "X_count = count.fit_transform(df['palabras'])\n",
    "print(X_count.shape)\n",
    "X_count.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = CountVectorizer(binary=True)\n",
    "X_dummy = dummy.fit_transform(df['palabras'])\n",
    "print(X_dummy.shape)\n",
    "X_dummy.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression logistica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(X_train, y_train)\n",
    "y_pred = modelLR.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train, y_train)\n",
    "y_pred = modelNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier()\n",
    "modelRF.fit(X_train, y_train)\n",
    "y_pred = modelRF.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones Archivo de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con el modelo a los siguientes Datos usando el mejor modelo LR\n",
    "\n",
    "df_pred = pd.read_csv('particion_prueba_estudiantes.csv')\n",
    "\n",
    "df_p = df_pred.copy()\n",
    "\n",
    "# Predecir con el modleo de Liner Regression\n",
    "df_p['Review'] = df_p['Review'].apply(remove_noise)\n",
    "df_p['Review'] = df_p['Review'].apply(clean_text)\n",
    "df_p['Review'] = df_p['Review'].apply(normalize_text)\n",
    "df_p['Review'] = df_p['Review'].apply(preprocess_text)\n",
    "X_pred = vectorizer.transform(df_p['Review']).toarray()\n",
    "y_pred = modelLR.predict(X_pred)\n",
    "df_p['Class'] = y_pred\n",
    "\n",
    "# Guardar predicciones\n",
    "df_pred['Class'] = y_pred\n",
    "df_pred.to_csv('predicciones_estudiantes.csv', index=False)\n",
    "print(df_p.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
